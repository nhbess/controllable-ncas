{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b91a0b5-20ed-4f4e-b38d-4e7f4fa98476",
   "metadata": {},
   "source": [
    "# Movable Emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1da83f-e282-4cce-8225-03e82fbdaebd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13118a5-38f6-424a-ba39-0426056580fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllable_nca.experiments.movable_emoji.trainer import MovableEmojiNCATrainer\n",
    "from controllable_nca.experiments.movable_emoji.movable_emoji_dataset import MovableEmojiDataset\n",
    "from controllable_nca.nca import ControllableNCA\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e97283-ce6f-42b8-9172-95e464be2bc7",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11225cfc-95d7-4c7a-8f88-c7e1107ccc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "from controllable_nca.dataset import NCADataset\n",
    "from controllable_nca.utils import load_emoji, rgb\n",
    "\n",
    "\n",
    "def plot_img(img):\n",
    "    with torch.no_grad():\n",
    "        rgb_image = rgb(img, False).squeeze().detach().cpu().numpy()\n",
    "    rgb_image = rearrange(rgb_image, \"c w h -> w h c\")\n",
    "    _ = plt.imshow(rgb_image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_in_grid(img, x=None, y=None, grid_size=64):\n",
    "    with torch.no_grad():\n",
    "        if x is None:\n",
    "            x = grid_size // 2\n",
    "        if y is None:\n",
    "            y = grid_size // 2\n",
    "\n",
    "        img_size = img.size(-1)\n",
    "        center = img_size // 2\n",
    "        grid = torch.zeros(1, img.size(1), grid_size, grid_size, device=img.device)\n",
    "\n",
    "        min_x = x - center\n",
    "        min_x_diff = 0 - min(0, min_x)\n",
    "        max_x = x + center\n",
    "        max_x_diff = grid_size - max(grid_size, max_x)\n",
    "        min_x = min_x + max_x_diff + min_x_diff\n",
    "        max_x = max_x + max_x_diff + min_x_diff\n",
    "\n",
    "        min_y = y - center\n",
    "        min_y_diff = 0 - min(0, min_y)\n",
    "        max_y = y + center\n",
    "        max_y_diff = grid_size - max(grid_size, max_y)\n",
    "        min_y = min_y + max_y_diff + min_y_diff\n",
    "        max_y = max_y + max_y_diff + min_y_diff\n",
    "\n",
    "        grid[:, :, min_x:max_x, min_y:max_y] += img\n",
    "        return grid, (min_x + center, min_y + center)\n",
    "\n",
    "\n",
    "class MovableEmojiDataset(NCADataset):\n",
    "    def __init__(self, emoji: str = \"ðŸ¦Ž\", grid_size=64, image_size=32):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.image_size = image_size\n",
    "        self.emoji = emoji\n",
    "        self.x = load_emoji(emoji, 40, image_size).unsqueeze(0)\n",
    "\n",
    "    def draw(self, x=None, y=None, substrate=None):\n",
    "        if substrate is None:\n",
    "            substrate = self.x\n",
    "        return draw_in_grid(substrate.clone(), x=x, y=y, grid_size=self.grid_size)\n",
    "\n",
    "    def target_size(self):\n",
    "        return (4, self.grid_size, self.grid_size)\n",
    "\n",
    "    def visualize(self, x=None, y=None):\n",
    "        grid, coords = self.draw(x, y)\n",
    "        plot_img(grid)\n",
    "\n",
    "    def to(self, device: torch.device):\n",
    "        self.x = self.x.to(device)\n",
    "\n",
    "    def num_goals(self) -> int:\n",
    "        return 5\n",
    "\n",
    "\n",
    "dataset = MovableEmojiDataset(grid_size=64, image_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e485a-62b8-46cf-a734-052b61834ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.visualize(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46b2c2-223e-4271-8eac-2a6615373ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.visualize(32, 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b665a9-4c7f-4eb5-98a7-146b00e301b5",
   "metadata": {},
   "source": [
    "### Make NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c0023-fa58-49c4-b3fe-26f21a0b48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_CHANNELS=32\n",
    "\n",
    "nca =  ControllableNCA(num_goals=dataset.num_goals(), target_shape=dataset.target_size(), living_channel_dim=3, num_hidden_channels=NUM_HIDDEN_CHANNELS, cell_fire_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04987c-c986-44af-8032-34d543ff9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "nca = nca.to(device)\n",
    "dataset.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1765c02-b2be-4087-bc5e-8c05a4e11493",
   "metadata": {},
   "source": [
    "### Make Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a2526-bc32-491a-a96b-c37392b77611",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MovableEmojiNCATrainer(nca, dataset, nca_steps=[48, 64], lr=1e-3, num_damaged=0, damage_radius=3, device=device, pool_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183288a-9272-4cf8-aa35-faab3586a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(batch_size=24, epochs=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b6cab-76c2-4b3b-8267-18fb81ede35e",
   "metadata": {},
   "source": [
    "## Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763491d9-21c2-4fce-86dd-5a104c4251e2",
   "metadata": {},
   "source": [
    "#### load pretrained nca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a3caa-76ca-4d90-b71b-a5a1f714840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nca.load(\"../saved_models/movable_salamander.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b91fe9-99f8-406f-9447-2b4bae860a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Event, Thread\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from ipycanvas import Canvas, hold_canvas  # noqa\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "\n",
    "from controllable_nca.experiments.movable_emoji.trainer import MovableEmojiNCATrainer\n",
    "from controllable_nca.utils import rgb\n",
    "\n",
    "\n",
    "def to_numpy_rgb(x, use_rgb=False):\n",
    "    return rearrange(\n",
    "        np.squeeze(rgb(x, use_rgb).detach().cpu().numpy()), \"c x y -> x y c\"\n",
    "    )\n",
    "\n",
    "\n",
    "class MovableEmojiVisualizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        trainer: MovableEmojiNCATrainer,\n",
    "        image_size,\n",
    "        rgb: bool = False,\n",
    "        canvas_scale=5,\n",
    "        damage_radius: int = 5,\n",
    "    ):\n",
    "        self.trainer = trainer\n",
    "        self.current_state = None\n",
    "        self.current_goal = None\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.rgb = rgb\n",
    "        self.canvas_scale = canvas_scale\n",
    "        self.canvas_size = self.image_size * self.canvas_scale\n",
    "\n",
    "        self.canvas = Canvas(width=self.canvas_size, height=self.canvas_size)\n",
    "        self.stopped = Event()\n",
    "\n",
    "        self.current_goal = torch.tensor(0, device=self.trainer.device)\n",
    "\n",
    "        self.device = self.trainer.device\n",
    "        self.damage_radius = damage_radius\n",
    "        self.current_state = self.trainer.nca.generate_seed(1).to(self.device)\n",
    "\n",
    "        def button_fn(class_num):\n",
    "            def start(btn):\n",
    "                self.current_goal = torch.tensor(class_num, device=self.trainer.device)\n",
    "                if self.stopped.isSet():\n",
    "                    self.stopped.clear()\n",
    "                    Thread(target=self.loop).start()\n",
    "\n",
    "            return start\n",
    "\n",
    "        button_list = []\n",
    "        for i in range(5):\n",
    "            button_list.append(Button(description=\"{}\".format(i)))\n",
    "            button_list[-1].on_click(button_fn(i))\n",
    "\n",
    "        self.vbox = VBox(button_list)\n",
    "\n",
    "        self.stop_btn = Button(description=\"Stop\")\n",
    "\n",
    "        def stop(btn):\n",
    "            if not self.stopped.isSet():\n",
    "                self.stopped.set()\n",
    "\n",
    "        self.stop_btn.on_click(stop)\n",
    "\n",
    "    def draw_image(self, rgb):\n",
    "        with hold_canvas(self.canvas):\n",
    "            rgb = np.squeeze(rearrange(rgb, \"b c w h -> b w h c\"))\n",
    "            self.canvas.clear()  # Clear the old animation step\n",
    "            self.canvas.put_image_data(\n",
    "                cv2.resize(\n",
    "                    rgb * 255.0,\n",
    "                    (self.canvas_size, self.canvas_size),\n",
    "                    interpolation=cv2.INTER_NEAREST,\n",
    "                ),\n",
    "                0,\n",
    "                0,\n",
    "            )\n",
    "\n",
    "    def loop(self):\n",
    "        with torch.no_grad():\n",
    "            self.current_state = self.trainer.nca.generate_seed(1).to(self.device)\n",
    "            while not self.stopped.wait(0.02):  # the first call is in `interval` secs\n",
    "                # update_particle_locations()\n",
    "                self.draw_image(self.trainer.to_rgb(self.current_state))\n",
    "                self.current_state = self.trainer.nca.grow(\n",
    "                    self.current_state, 1, self.current_goal\n",
    "                )\n",
    "\n",
    "    def visualize(self):\n",
    "        Thread(target=self.loop).start()\n",
    "        display(self.canvas, HBox([self.stop_btn, self.vbox]))  # noqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = MovableEmojiVisualizer(trainer, 64)\n",
    "viz.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e581c6-d2c9-4c06-99ca-bb1448deb01b",
   "metadata": {},
   "source": [
    "## Test Goal Dropout with various values for cell_fire_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a4478-b87f-4730-a449-ca8984df1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplt as plt\n",
    "\n",
    "def get_movements(trainer, cell_fire_rate=1.0):\n",
    "    original_cell_fire_rate = trainer.nca.cell_fire_rate \n",
    "    trainer.nca.cell_fire_rate = cell_fire_rate\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = trainer.nca.generate_seed(1, size=128).to(trainer.device)\n",
    "        rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "        out = [rgb]\n",
    "\n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(1, device=trainer.device)\n",
    "        for i in range(128):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            # out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(3, device=trainer.device)\n",
    "        for i in range(128):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            # out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(2, device=trainer.device)\n",
    "        for i in range(256):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "    \n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            # out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(4, device=trainer.device)\n",
    "        for i in range(128):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            # out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(2, device=trainer.device)\n",
    "        for i in range(256):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            # out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(4, device=trainer.device)\n",
    "        for i in range(64):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            out.append(rgb)\n",
    "\n",
    "        current_goal = torch.tensor(0, device=trainer.device)\n",
    "        for i in range(96):\n",
    "            x = trainer.nca.grow(\n",
    "                        x, 1, current_goal\n",
    "                    )\n",
    "            rgb = np.squeeze(rearrange(trainer.to_rgb(x), \"b c w h -> b w h c\"))\n",
    "            # out.append(rgb)\n",
    "        trainer.nca.cell_fire_rate = original_cell_fire_rate\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0475c70-bf94-40d1-b371-fce194f32d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "\n",
    "outs = get_movements(trainer)\n",
    "\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "for substrate in outs:\n",
    "    plt.imshow(substrate)\n",
    "    camera.snap()\n",
    "animation = camera.animate(blit = False, interval = 16)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a990456-e7ef-439b-8cb6-8d187d02f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "\n",
    "outs = get_movements(trainer, cell_fire_rate=0.5)\n",
    "\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "for substrate in outs:\n",
    "    plt.imshow(substrate)\n",
    "    camera.snap()\n",
    "animation = camera.animate(blit = False, interval = 16)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796f0b3-827f-440d-8121-c1b323312213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from celluloid import Camera\n",
    "\n",
    "outs = get_movements(trainer, cell_fire_rate=0.25)\n",
    "\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "for substrate in outs:\n",
    "    plt.imshow(substrate)\n",
    "    camera.snap()\n",
    "animation = camera.animate(blit = False, interval = 16)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(animation.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d64cb66d3d902aa83000daa06ca958bef94bde318911a82aee5f8df2bb8934b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
